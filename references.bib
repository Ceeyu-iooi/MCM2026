











@article{toupiao,
	title = {'Dancing with the audience': Administrating vote-ins in public and commercial broadcasting},
	volume = {33},
	shorttitle = {'Dancing with the audience'},
	pages = {953--962},
	journaltitle = {Media, Culture \& Society},
	shortjournal = {Media, Culture \& Society},
	author = {Enli, Gunn and Ihlebæk, Karoline},
	date = {2011-09-01},
	file = {Full Text PDF:C\:\\Users\\HP\\Zotero\\storage\\6Z5NTNJ5\\Enli和Ihlebæk - 2011 - 'Dancing with the audience' Administrating vote-ins in public and commercial broadcasting.pdf:application/pdf},
}


@incollection{inverse,
	location = {Berlin, Heidelberg},
	title = {Inverse Problems in Statistics},
	abstract = {There exist many fields where inverse problems appear. Some examples are: astronomy (blurred images of the Hubble satellite), econometrics (instrumental variables), financial mathematics (model calibration of the volatility), medical image processing (X-ray tomography), and quantum physics (quantum homodyne tomography). These are problems where we have indirect observations of an object (a function) that we want to reconstruct, through a linear operator A. Due to its indirect nature, solving an inverse problem is usually rather difficult. For this reason, one needs regularization methods in order to get a stable and accurate reconstruction. We present the framework of statistical inverse problems where the data are corrupted by some stochastic error. This white noise model may be discretized in the spectral domain using Singular Value Decomposition ({SVD}), when the operator A is compact. Several examples of inverse problems where the {SVD} is known are presented (circular deconvolution, heat equation, tomography). We explain some basic issues regarding nonparametric statistics applied to inverse problems. Standard regularization methods and their counterpart as estimation procedures by use of {SVD} are discussed (projection, Landweber, Tikhonov, . . . ). Several classical statistical approaches like minimax risk and optimal rates of convergence, are presented. This notion of optimality leads to some optimal choice of the tuning parameter. However these optimal parameters are unachievable since they depend on the unknown smoothness of the function. This leads to more recent concepts like adaptive estimation and oracle inequalities. Several data-driven selection procedures of the regularization parameter are discussed in details, among these: model selection methods, Stein’s unbiased risk estimation and the recent risk hull method.},
	pages = {3--96},
	booktitle = {Inverse Problems and High-Dimensional Estimation: Stats in the Château Summer School, August 31 - September 4, 2009},
	publisher = {Springer},
	author = {Cavalier, Laurent},
	editor = {Alquier, Pierre and Gautier, Eric and Stoltz, Gilles},
	date = {2011},
	langid = {english},
	keywords = {Inverse Problem, Optimal Rate, Projection Estimator, Regularization Method, Singular Value Decomposition},
}

@book{beiyesi,
	location = {New York},
	edition = {2},
	title = {Statistical Rethinking: A Bayesian Course with Examples in R and {STAN}},
	shorttitle = {Statistical Rethinking},
	publisher = {Chapman and Hall/{CRC}},
	author = {{McElreath}, Richard},
	date = {2020-03-13},
}


@article{gershman_statistics_2012,
	title = {Statistics in the Ballroom: Analyzing Voting Data from Dancing with the Stars},
	shorttitle = {Statistics in the Ballroom},
	journaltitle = {Mathematics Faculty Proceedings, Presentations, Speeches, Lectures},
	author = {Gershman, Jason},
	date = {2012-04-18},
	file = {text/html Attachment:C\:\\Users\\HP\\Zotero\\storage\\PRA7GCPP\\189.html:text/html},
}


@book{arrow_social_2012,
	title = {Social Choice and Individual Values},
	abstract = {Originally published in 1951, \textit{Social Choice and Individual Values} introduced "Arrow's Impossibility Theorem" and founded the field of social choice theory in economics and political science. This new edition, including a new foreword by Nobel laureate Eric Maskin, reintroduces Arrow's seminal book to a new generation of students and researchers.  "Far beyond a classic, this small book unleashed the ongoing explosion of interest in social choice and voting theory. A half-century later, the book remains full of profound insight: its central message, 'Arrow's Theorem,' has changed the way we think."-Donald G. Saari, author of \textit{Decisions and Elections: Explaining the Unexpected}},
	publisher = {Yale University Press},
	author = {Arrow, Kenneth J.},
	date = {2012},
}




@article{neuberg_causality_2003,
	title = {{CAUSALITY}: {MODELS}, {REASONING}, {AND} {INFERENCE}, by Judea Pearl, Cambridge University Press, 2000},
	volume = {19},
	shorttitle = {{CAUSALITY}},
	abstract = {This book seeks to integrate research on cause and effect inference from cognitive science, econometrics, epidemiology, philosophy, and statistics. It puts forward the work of its author, his collaborators, and others over the past two decades as a new account of cause and effect inference that can aid practical researchers in many fields, including econometrics. Pearl adheres to several propositions on cause and effect inference. Though cause and effect relations are fundamentally deterministic (he explicitly excludes quantum mechanical phenomena from his concept of cause and effect), cause and effect analysis involves probability language. Probability language helps to convey uncertainty about cause and effect relations but is insufficient to fully express those relations. In addition to conditional probabilities of events, cause and effect analysis requires graphs or diagrams and a language that distinguishes intervention or manipulation from observation. Cause and effect analysis also requires counterfactual reasoning and causal assumptions in addition to observations and statistical assumptions.},
	pages = {675--685},
	number = {4},
	journaltitle = {Econometric Theory},
	author = {Neuberg, Leland Gerson},

	date = {2003-08},
	langid = {english},
}

@book{saltelli_sensitivity_2000,
	title = {Sensitivity Analysis},
	volume = {134},
	author = {Saltelli, Andrea and Chan, K and Scott, E.Marian},
	date = {2000-01-01},
}

@article{laird_random-effects_1982,
	title = {Random-Effects Models for Longitudinal Data},
	volume = {38},
	abstract = {Models for the analysis of longitudinal data must recognize the relationship between serial observations on the same unit. Multivariate models with general covariance structure are often difficult to apply to highly unbalanced data, whereas two-stage random-effects models can be used easily. In two-stage models, the probability distributions for the response vectors of different individuals belong to a single family, but some random-effects parameters vary across individuals, with a distribution specified at the second stage. A general family of models is discussed, which includes both growth models and repeated-measures models as special cases. A unified approach to fitting these models, based on a combination of empirical Bayes and maximum likelihood estimation of model parameters and using the {EM} algorithm, is discussed. Two examples are taken from a current epidemiological study of the health effects of air pollution.},
	pages = {963--974},
	number = {4},
	journaltitle = {Biometrics},
	publisher = {[Wiley, International Biometric Society]},
	author = {Laird, Nan M. and Ware, James H.},
	date = {1982},
}


